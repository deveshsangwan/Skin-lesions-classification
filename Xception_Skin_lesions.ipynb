{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Xception_Skin_lesions.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMV5GWW2eOmxg0qmEFsuuLl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deveshsangwan/Skin-lesions-classification/blob/main/Xception_Skin_lesions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_MHvF5A6FMP"
      },
      "source": [
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-zNMgRA6JYf"
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1YKPp6A6Kyr"
      },
      "source": [
        "import os\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical # convert to one-hot-encoding\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications.xception import Xception, preprocess_input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYlYFKF46MNY",
        "outputId": "979c1bd5-c16d-4087-8740-cb9228464167",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmK35N9e27Qu"
      },
      "source": [
        "y_train = np.load(\"/content/drive/My Drive/Datasets/Skin_npy/y_train.npy\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjHPwOaZ1A8X"
      },
      "source": [
        "X_train = np.load(\"/content/drive/My Drive/Datasets/Skin_npy/x_train.npy\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-jVIN2K3enb"
      },
      "source": [
        "X_val = np.load(\"/content/drive/My Drive/Datasets/Skin_npy/x_validate.npy\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdB-cl6W3nl2"
      },
      "source": [
        "y_val = np.load(\"/content/drive/My Drive/Datasets/Skin_npy/y_validate.npy\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlN931Yg3vUh",
        "outputId": "8eae86b1-0f40-4f55-e3dd-491bb9ac3e06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape, X_val.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7210, 192, 256, 3), (802, 192, 256, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMKYGSdY3zwF",
        "outputId": "41cdc14c-4fec-4536-d44e-ebed769c6cbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train.shape, y_val.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7210, 7), (802, 7))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zziPRxl_4QQn",
        "outputId": "244cc4ca-9847-40b1-8916-b9de6d6968a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "pre_trained_model = Xception(input_shape=(192, 256, 3), include_top=False, weights=\"imagenet\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vWG_UfB4cIG",
        "outputId": "c3fc8844-f64d-421e-b27c-b904b3a733ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for layer in pre_trained_model.layers:\n",
        "    print(layer.name)\n",
        "    layer.trainable = False\n",
        "    \n",
        "print(len(pre_trained_model.layers))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_1\n",
            "block1_conv1\n",
            "block1_conv1_bn\n",
            "block1_conv1_act\n",
            "block1_conv2\n",
            "block1_conv2_bn\n",
            "block1_conv2_act\n",
            "block2_sepconv1\n",
            "block2_sepconv1_bn\n",
            "block2_sepconv2_act\n",
            "block2_sepconv2\n",
            "block2_sepconv2_bn\n",
            "conv2d\n",
            "block2_pool\n",
            "batch_normalization\n",
            "add\n",
            "block3_sepconv1_act\n",
            "block3_sepconv1\n",
            "block3_sepconv1_bn\n",
            "block3_sepconv2_act\n",
            "block3_sepconv2\n",
            "block3_sepconv2_bn\n",
            "conv2d_1\n",
            "block3_pool\n",
            "batch_normalization_1\n",
            "add_1\n",
            "block4_sepconv1_act\n",
            "block4_sepconv1\n",
            "block4_sepconv1_bn\n",
            "block4_sepconv2_act\n",
            "block4_sepconv2\n",
            "block4_sepconv2_bn\n",
            "conv2d_2\n",
            "block4_pool\n",
            "batch_normalization_2\n",
            "add_2\n",
            "block5_sepconv1_act\n",
            "block5_sepconv1\n",
            "block5_sepconv1_bn\n",
            "block5_sepconv2_act\n",
            "block5_sepconv2\n",
            "block5_sepconv2_bn\n",
            "block5_sepconv3_act\n",
            "block5_sepconv3\n",
            "block5_sepconv3_bn\n",
            "add_3\n",
            "block6_sepconv1_act\n",
            "block6_sepconv1\n",
            "block6_sepconv1_bn\n",
            "block6_sepconv2_act\n",
            "block6_sepconv2\n",
            "block6_sepconv2_bn\n",
            "block6_sepconv3_act\n",
            "block6_sepconv3\n",
            "block6_sepconv3_bn\n",
            "add_4\n",
            "block7_sepconv1_act\n",
            "block7_sepconv1\n",
            "block7_sepconv1_bn\n",
            "block7_sepconv2_act\n",
            "block7_sepconv2\n",
            "block7_sepconv2_bn\n",
            "block7_sepconv3_act\n",
            "block7_sepconv3\n",
            "block7_sepconv3_bn\n",
            "add_5\n",
            "block8_sepconv1_act\n",
            "block8_sepconv1\n",
            "block8_sepconv1_bn\n",
            "block8_sepconv2_act\n",
            "block8_sepconv2\n",
            "block8_sepconv2_bn\n",
            "block8_sepconv3_act\n",
            "block8_sepconv3\n",
            "block8_sepconv3_bn\n",
            "add_6\n",
            "block9_sepconv1_act\n",
            "block9_sepconv1\n",
            "block9_sepconv1_bn\n",
            "block9_sepconv2_act\n",
            "block9_sepconv2\n",
            "block9_sepconv2_bn\n",
            "block9_sepconv3_act\n",
            "block9_sepconv3\n",
            "block9_sepconv3_bn\n",
            "add_7\n",
            "block10_sepconv1_act\n",
            "block10_sepconv1\n",
            "block10_sepconv1_bn\n",
            "block10_sepconv2_act\n",
            "block10_sepconv2\n",
            "block10_sepconv2_bn\n",
            "block10_sepconv3_act\n",
            "block10_sepconv3\n",
            "block10_sepconv3_bn\n",
            "add_8\n",
            "block11_sepconv1_act\n",
            "block11_sepconv1\n",
            "block11_sepconv1_bn\n",
            "block11_sepconv2_act\n",
            "block11_sepconv2\n",
            "block11_sepconv2_bn\n",
            "block11_sepconv3_act\n",
            "block11_sepconv3\n",
            "block11_sepconv3_bn\n",
            "add_9\n",
            "block12_sepconv1_act\n",
            "block12_sepconv1\n",
            "block12_sepconv1_bn\n",
            "block12_sepconv2_act\n",
            "block12_sepconv2\n",
            "block12_sepconv2_bn\n",
            "block12_sepconv3_act\n",
            "block12_sepconv3\n",
            "block12_sepconv3_bn\n",
            "add_10\n",
            "block13_sepconv1_act\n",
            "block13_sepconv1\n",
            "block13_sepconv1_bn\n",
            "block13_sepconv2_act\n",
            "block13_sepconv2\n",
            "block13_sepconv2_bn\n",
            "conv2d_3\n",
            "block13_pool\n",
            "batch_normalization_3\n",
            "add_11\n",
            "block14_sepconv1\n",
            "block14_sepconv1_bn\n",
            "block14_sepconv1_act\n",
            "block14_sepconv2\n",
            "block14_sepconv2_bn\n",
            "block14_sepconv2_act\n",
            "132\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkUG7SfH4jN0",
        "outputId": "749c0193-0cd6-435d-8745-6c155602f020",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('block14_sepconv2_act')\n",
        "print('last layer output shape:', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape: (None, 6, 8, 2048)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ktpcpv0g4qFt"
      },
      "source": [
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.GlobalMaxPooling2D()(last_output)\n",
        "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "# Add a dropout rate of 0.5\n",
        "x = layers.Dropout(0.5)(x)\n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(7, activation='softmax')(x)\n",
        "\n",
        "# Configure and compile the model\n",
        "\n",
        "model = Model(pre_trained_model.input, x)\n",
        "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuY2oElT45-s"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=90,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=True,  # randomly flip images\n",
        "        shear_range = 10)\n",
        "\n",
        "train_datagen.fit(X_train)\n",
        "\n",
        "val_datagen = ImageDataGenerator()\n",
        "val_datagen.fit(X_val)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBWK621D5TK1"
      },
      "source": [
        "for layer in pre_trained_model.layers:\n",
        "    layer.trainable = True"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRXzeiEF5nk3"
      },
      "source": [
        "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlAVa1em5qiN"
      },
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, \n",
        "                                            min_lr=0.000001, cooldown=2)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "up-S_ilj5vO3",
        "outputId": "57747a38-d5e1-43ca-ca94-2913836492da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 192, 256, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 95, 127, 32)  864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_bn (BatchNormaliza (None, 95, 127, 32)  128         block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_act (Activation)   (None, 95, 127, 32)  0           block1_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 93, 125, 64)  18432       block1_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_bn (BatchNormaliza (None, 93, 125, 64)  256         block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_act (Activation)   (None, 93, 125, 64)  0           block1_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1 (SeparableConv2 (None, 93, 125, 128) 8768        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1_bn (BatchNormal (None, 93, 125, 128) 512         block2_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_act (Activation (None, 93, 125, 128) 0           block2_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2 (SeparableConv2 (None, 93, 125, 128) 17536       block2_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_bn (BatchNormal (None, 93, 125, 128) 512         block2_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 47, 63, 128)  8192        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 47, 63, 128)  0           block2_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 47, 63, 128)  512         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 47, 63, 128)  0           block2_pool[0][0]                \n",
            "                                                                 batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_act (Activation (None, 47, 63, 128)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1 (SeparableConv2 (None, 47, 63, 256)  33920       block3_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_bn (BatchNormal (None, 47, 63, 256)  1024        block3_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_act (Activation (None, 47, 63, 256)  0           block3_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2 (SeparableConv2 (None, 47, 63, 256)  67840       block3_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_bn (BatchNormal (None, 47, 63, 256)  1024        block3_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 24, 32, 256)  32768       add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 24, 32, 256)  0           block3_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 24, 32, 256)  1024        conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 24, 32, 256)  0           block3_pool[0][0]                \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_act (Activation (None, 24, 32, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1 (SeparableConv2 (None, 24, 32, 728)  188672      block4_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_bn (BatchNormal (None, 24, 32, 728)  2912        block4_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_act (Activation (None, 24, 32, 728)  0           block4_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2 (SeparableConv2 (None, 24, 32, 728)  536536      block4_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_bn (BatchNormal (None, 24, 32, 728)  2912        block4_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 12, 16, 728)  186368      add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 12, 16, 728)  0           block4_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 12, 16, 728)  2912        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 12, 16, 728)  0           block4_pool[0][0]                \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_act (Activation (None, 12, 16, 728)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1 (SeparableConv2 (None, 12, 16, 728)  536536      block5_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_bn (BatchNormal (None, 12, 16, 728)  2912        block5_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_act (Activation (None, 12, 16, 728)  0           block5_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2 (SeparableConv2 (None, 12, 16, 728)  536536      block5_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_bn (BatchNormal (None, 12, 16, 728)  2912        block5_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_act (Activation (None, 12, 16, 728)  0           block5_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3 (SeparableConv2 (None, 12, 16, 728)  536536      block5_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_bn (BatchNormal (None, 12, 16, 728)  2912        block5_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 12, 16, 728)  0           block5_sepconv3_bn[0][0]         \n",
            "                                                                 add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_act (Activation (None, 12, 16, 728)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1 (SeparableConv2 (None, 12, 16, 728)  536536      block6_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_bn (BatchNormal (None, 12, 16, 728)  2912        block6_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_act (Activation (None, 12, 16, 728)  0           block6_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2 (SeparableConv2 (None, 12, 16, 728)  536536      block6_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_bn (BatchNormal (None, 12, 16, 728)  2912        block6_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_act (Activation (None, 12, 16, 728)  0           block6_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3 (SeparableConv2 (None, 12, 16, 728)  536536      block6_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_bn (BatchNormal (None, 12, 16, 728)  2912        block6_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 12, 16, 728)  0           block6_sepconv3_bn[0][0]         \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_act (Activation (None, 12, 16, 728)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1 (SeparableConv2 (None, 12, 16, 728)  536536      block7_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_bn (BatchNormal (None, 12, 16, 728)  2912        block7_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_act (Activation (None, 12, 16, 728)  0           block7_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2 (SeparableConv2 (None, 12, 16, 728)  536536      block7_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_bn (BatchNormal (None, 12, 16, 728)  2912        block7_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_act (Activation (None, 12, 16, 728)  0           block7_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3 (SeparableConv2 (None, 12, 16, 728)  536536      block7_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_bn (BatchNormal (None, 12, 16, 728)  2912        block7_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 12, 16, 728)  0           block7_sepconv3_bn[0][0]         \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_act (Activation (None, 12, 16, 728)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1 (SeparableConv2 (None, 12, 16, 728)  536536      block8_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_bn (BatchNormal (None, 12, 16, 728)  2912        block8_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_act (Activation (None, 12, 16, 728)  0           block8_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2 (SeparableConv2 (None, 12, 16, 728)  536536      block8_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_bn (BatchNormal (None, 12, 16, 728)  2912        block8_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_act (Activation (None, 12, 16, 728)  0           block8_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3 (SeparableConv2 (None, 12, 16, 728)  536536      block8_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_bn (BatchNormal (None, 12, 16, 728)  2912        block8_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 12, 16, 728)  0           block8_sepconv3_bn[0][0]         \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_act (Activation (None, 12, 16, 728)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1 (SeparableConv2 (None, 12, 16, 728)  536536      block9_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_bn (BatchNormal (None, 12, 16, 728)  2912        block9_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_act (Activation (None, 12, 16, 728)  0           block9_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2 (SeparableConv2 (None, 12, 16, 728)  536536      block9_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_bn (BatchNormal (None, 12, 16, 728)  2912        block9_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_act (Activation (None, 12, 16, 728)  0           block9_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3 (SeparableConv2 (None, 12, 16, 728)  536536      block9_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_bn (BatchNormal (None, 12, 16, 728)  2912        block9_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 12, 16, 728)  0           block9_sepconv3_bn[0][0]         \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_act (Activatio (None, 12, 16, 728)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1 (SeparableConv (None, 12, 16, 728)  536536      block10_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_bn (BatchNorma (None, 12, 16, 728)  2912        block10_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_act (Activatio (None, 12, 16, 728)  0           block10_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2 (SeparableConv (None, 12, 16, 728)  536536      block10_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_bn (BatchNorma (None, 12, 16, 728)  2912        block10_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_act (Activatio (None, 12, 16, 728)  0           block10_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3 (SeparableConv (None, 12, 16, 728)  536536      block10_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_bn (BatchNorma (None, 12, 16, 728)  2912        block10_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 12, 16, 728)  0           block10_sepconv3_bn[0][0]        \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_act (Activatio (None, 12, 16, 728)  0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1 (SeparableConv (None, 12, 16, 728)  536536      block11_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_bn (BatchNorma (None, 12, 16, 728)  2912        block11_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_act (Activatio (None, 12, 16, 728)  0           block11_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2 (SeparableConv (None, 12, 16, 728)  536536      block11_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_bn (BatchNorma (None, 12, 16, 728)  2912        block11_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_act (Activatio (None, 12, 16, 728)  0           block11_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3 (SeparableConv (None, 12, 16, 728)  536536      block11_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_bn (BatchNorma (None, 12, 16, 728)  2912        block11_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 12, 16, 728)  0           block11_sepconv3_bn[0][0]        \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_act (Activatio (None, 12, 16, 728)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1 (SeparableConv (None, 12, 16, 728)  536536      block12_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_bn (BatchNorma (None, 12, 16, 728)  2912        block12_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_act (Activatio (None, 12, 16, 728)  0           block12_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2 (SeparableConv (None, 12, 16, 728)  536536      block12_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_bn (BatchNorma (None, 12, 16, 728)  2912        block12_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_act (Activatio (None, 12, 16, 728)  0           block12_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3 (SeparableConv (None, 12, 16, 728)  536536      block12_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_bn (BatchNorma (None, 12, 16, 728)  2912        block12_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 12, 16, 728)  0           block12_sepconv3_bn[0][0]        \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_act (Activatio (None, 12, 16, 728)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1 (SeparableConv (None, 12, 16, 728)  536536      block13_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_bn (BatchNorma (None, 12, 16, 728)  2912        block13_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_act (Activatio (None, 12, 16, 728)  0           block13_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2 (SeparableConv (None, 12, 16, 1024) 752024      block13_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_bn (BatchNorma (None, 12, 16, 1024) 4096        block13_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 6, 8, 1024)   745472      add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_pool (MaxPooling2D)     (None, 6, 8, 1024)   0           block13_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 6, 8, 1024)   4096        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 6, 8, 1024)   0           block13_pool[0][0]               \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1 (SeparableConv (None, 6, 8, 1536)   1582080     add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_bn (BatchNorma (None, 6, 8, 1536)   6144        block14_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_act (Activatio (None, 6, 8, 1536)   0           block14_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2 (SeparableConv (None, 6, 8, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_bn (BatchNorma (None, 6, 8, 2048)   8192        block14_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_act (Activatio (None, 6, 8, 2048)   0           block14_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d (GlobalMax (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 512)          1049088     global_max_pooling2d[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 512)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 7)            3591        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 21,914,159\n",
            "Trainable params: 21,859,631\n",
            "Non-trainable params: 54,528\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o_SdmHC9qqt",
        "outputId": "3e207804-d8c6-4bfa-fd1f-043bf07199a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "batch_size = 64\n",
        "epochs = 35\n",
        "history = model.fit_generator(train_datagen.flow(X_train,y_train, batch_size=batch_size),\n",
        "                              epochs = epochs, validation_data = val_datagen.flow(X_val, y_val),\n",
        "                              verbose = 1, steps_per_epoch=(X_train.shape[0] // batch_size),\n",
        "                              validation_steps=(X_val.shape[0] // batch_size),\n",
        "                              callbacks=[learning_rate_reduction])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-20-b0e0df1b87c2>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/35\n",
            "  2/112 [..............................] - ETA: 2:11 - loss: 2.3092 - acc: 0.2578WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.6564s vs `on_train_batch_end` time: 1.7276s). Check your callbacks.\n",
            "112/112 [==============================] - 271s 2s/step - loss: 0.9521 - acc: 0.6836 - val_loss: 1.2769 - val_acc: 0.7005\n",
            "Epoch 2/35\n",
            "112/112 [==============================] - 267s 2s/step - loss: 0.6652 - acc: 0.7702 - val_loss: 0.6571 - val_acc: 0.7760\n",
            "Epoch 3/35\n",
            "112/112 [==============================] - 266s 2s/step - loss: 0.5372 - acc: 0.8142 - val_loss: 0.5782 - val_acc: 0.7917\n",
            "Epoch 4/35\n",
            "112/112 [==============================] - 267s 2s/step - loss: 0.4482 - acc: 0.8382 - val_loss: 0.5153 - val_acc: 0.8177\n",
            "Epoch 5/35\n",
            "112/112 [==============================] - 268s 2s/step - loss: 0.3819 - acc: 0.8636 - val_loss: 0.5535 - val_acc: 0.7812\n",
            "Epoch 6/35\n",
            "112/112 [==============================] - 269s 2s/step - loss: 0.3330 - acc: 0.8832 - val_loss: 0.5174 - val_acc: 0.8021\n",
            "Epoch 7/35\n",
            "112/112 [==============================] - 269s 2s/step - loss: 0.2852 - acc: 0.8948 - val_loss: 0.4189 - val_acc: 0.8490\n",
            "Epoch 8/35\n",
            "112/112 [==============================] - 269s 2s/step - loss: 0.2564 - acc: 0.9020 - val_loss: 0.5689 - val_acc: 0.7995\n",
            "Epoch 9/35\n",
            "112/112 [==============================] - 269s 2s/step - loss: 0.2193 - acc: 0.9200 - val_loss: 0.4988 - val_acc: 0.8464\n",
            "Epoch 10/35\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.1976 - acc: 0.9267\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "112/112 [==============================] - 269s 2s/step - loss: 0.1976 - acc: 0.9267 - val_loss: 0.5286 - val_acc: 0.8359\n",
            "Epoch 11/35\n",
            "112/112 [==============================] - 270s 2s/step - loss: 0.1566 - acc: 0.9443 - val_loss: 0.5003 - val_acc: 0.8203\n",
            "Epoch 12/35\n",
            "112/112 [==============================] - 270s 2s/step - loss: 0.1359 - acc: 0.9527 - val_loss: 0.5105 - val_acc: 0.8542\n",
            "Epoch 13/35\n",
            "112/112 [==============================] - 269s 2s/step - loss: 0.1202 - acc: 0.9528 - val_loss: 0.5799 - val_acc: 0.8411\n",
            "Epoch 14/35\n",
            "112/112 [==============================] - 269s 2s/step - loss: 0.1210 - acc: 0.9554 - val_loss: 0.5505 - val_acc: 0.8490\n",
            "Epoch 15/35\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.1034 - acc: 0.9621\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "112/112 [==============================] - 269s 2s/step - loss: 0.1034 - acc: 0.9621 - val_loss: 0.6753 - val_acc: 0.8229\n",
            "Epoch 16/35\n",
            "112/112 [==============================] - 268s 2s/step - loss: 0.0889 - acc: 0.9675 - val_loss: 0.6108 - val_acc: 0.8594\n",
            "Epoch 17/35\n",
            "112/112 [==============================] - 270s 2s/step - loss: 0.0809 - acc: 0.9691 - val_loss: 0.4623 - val_acc: 0.8802\n",
            "Epoch 18/35\n",
            "112/112 [==============================] - 268s 2s/step - loss: 0.0681 - acc: 0.9758 - val_loss: 0.5968 - val_acc: 0.8672\n",
            "Epoch 19/35\n",
            "112/112 [==============================] - 265s 2s/step - loss: 0.0644 - acc: 0.9751 - val_loss: 0.6445 - val_acc: 0.8646\n",
            "Epoch 20/35\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.0608 - acc: 0.9790\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "112/112 [==============================] - 265s 2s/step - loss: 0.0608 - acc: 0.9790 - val_loss: 0.7303 - val_acc: 0.8438\n",
            "Epoch 21/35\n",
            "112/112 [==============================] - 266s 2s/step - loss: 0.0518 - acc: 0.9832 - val_loss: 0.6727 - val_acc: 0.8516\n",
            "Epoch 22/35\n",
            "112/112 [==============================] - 267s 2s/step - loss: 0.0521 - acc: 0.9810 - val_loss: 0.7327 - val_acc: 0.8411\n",
            "Epoch 23/35\n",
            "112/112 [==============================] - 268s 2s/step - loss: 0.0545 - acc: 0.9796 - val_loss: 0.8687 - val_acc: 0.8464\n",
            "Epoch 24/35\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.0511 - acc: 0.9821\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
            "112/112 [==============================] - 265s 2s/step - loss: 0.0511 - acc: 0.9821 - val_loss: 0.7942 - val_acc: 0.8568\n",
            "Epoch 25/35\n",
            "112/112 [==============================] - 266s 2s/step - loss: 0.0460 - acc: 0.9835 - val_loss: 0.7221 - val_acc: 0.8516\n",
            "Epoch 26/35\n",
            "112/112 [==============================] - 266s 2s/step - loss: 0.0502 - acc: 0.9828 - val_loss: 0.6035 - val_acc: 0.8750\n",
            "Epoch 27/35\n",
            "112/112 [==============================] - 267s 2s/step - loss: 0.0394 - acc: 0.9853 - val_loss: 0.7280 - val_acc: 0.8594\n",
            "Epoch 28/35\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.0391 - acc: 0.9850\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
            "112/112 [==============================] - 267s 2s/step - loss: 0.0391 - acc: 0.9850 - val_loss: 0.7757 - val_acc: 0.8490\n",
            "Epoch 29/35\n",
            "112/112 [==============================] - 267s 2s/step - loss: 0.0416 - acc: 0.9859 - val_loss: 0.7756 - val_acc: 0.8516\n",
            "Epoch 30/35\n",
            "112/112 [==============================] - 267s 2s/step - loss: 0.0405 - acc: 0.9856 - val_loss: 0.7458 - val_acc: 0.8438\n",
            "Epoch 31/35\n",
            "112/112 [==============================] - 266s 2s/step - loss: 0.0363 - acc: 0.9877 - val_loss: 0.7818 - val_acc: 0.8516\n",
            "Epoch 32/35\n",
            "112/112 [==============================] - ETA: 0s - loss: 0.0386 - acc: 0.9856\n",
            "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
            "112/112 [==============================] - 266s 2s/step - loss: 0.0386 - acc: 0.9856 - val_loss: 0.7934 - val_acc: 0.8490\n",
            "Epoch 33/35\n",
            "112/112 [==============================] - 267s 2s/step - loss: 0.0391 - acc: 0.9874 - val_loss: 0.8906 - val_acc: 0.8307\n",
            "Epoch 34/35\n",
            "112/112 [==============================] - 266s 2s/step - loss: 0.0394 - acc: 0.9861 - val_loss: 0.7786 - val_acc: 0.8568\n",
            "Epoch 35/35\n",
            "112/112 [==============================] - 267s 2s/step - loss: 0.0392 - acc: 0.9860 - val_loss: 0.6762 - val_acc: 0.8672\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gplTKEov90d",
        "outputId": "495b5a8c-3cf7-49b5-e60c-1fc0570d66cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "loss_val, acc_val = model.evaluate(X_val, y_val, verbose=1)\n",
        "print(\"Validation: accuracy = %f  ;  loss_v = %f\" % (acc_val, loss_val))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26/26 [==============================] - 8s 303ms/step - loss: 0.7449 - acc: 0.8616\n",
            "Validation: accuracy = 0.861596  ;  loss_v = 0.744947\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTd9gbZVwHHA"
      },
      "source": [
        "X_test = np.load(\"/content/drive/My Drive/Datasets/Skin_npy/x_test.npy\")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k01CDQqYwQ7P"
      },
      "source": [
        "y_test = np.load(\"/content/drive/My Drive/Datasets/Skin_npy/y_test.npy\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePURn6wAwVqu",
        "outputId": "129efce6-2c8d-48cb-947a-1c5a7b77efbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "loss_test, acc_test = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(\"Test: accuracy = %f  ;  loss = %f\" % (acc_test, loss_test))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 20s 315ms/step - loss: 0.8008 - acc: 0.8457\n",
            "Test: accuracy = 0.845731  ;  loss = 0.800797\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzL4kXubwX3R"
      },
      "source": [
        "model.save(\"/content/drive/My Drive/Xception.h5\")"
      ],
      "execution_count": 26,
      "outputs": []
    }
  ]
}